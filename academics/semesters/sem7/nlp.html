<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>TRAJECTORY</title>
    <link rel = "icon" class="log" href = 
    "./../../../images/icons8-open-book-emoji-48.png" 
            type = "image/x-icon">
    <link rel="stylesheet" href="../../../homestyle.css">
    <link rel="stylesheet" href="../sem7/semester7.css">
    <link rel="stylesheet" href="/main pages/academics/academicsstyle.css">
    <!-- google font(MONTSERRAT) -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400;500;600;700;800;900&display=swap"
        rel="stylesheet">

</head>

<body>
    <nav class="header">
        <img class="log" src="../../../images/Trajectory.svg">
        <a class="logo" href="../../../index.html">TRAJECTORY</a>
        <input class="menu-btn" type="checkbox" id="menu-btn" />
        <label class="menu-icon" for="menu-btn"><span class="navicon"></span></label>
        <ul class="menu">
            <li><a href="../../../index.html" class="link link-theme link-arrow" style="
                display: inline-block;
                position: relative;
                border: none;
                padding-bottom: 4px;
                text-transform: uppercase;
                font-family: Montserrat, helvetica, arial, sans-serif;
                font-weight: 700
              ">HOME</a></li>
              <li><a href="../../academics.html" class="link link-theme link-arrow" style="
                display: inline-block;
                position: relative;
                border: none;
                padding-bottom: 4px;
                text-transform: uppercase;
                font-family: Montserrat, helvetica, arial, sans-serif;
                font-weight: 700
              ">Academics</a></li>
              <li><a href="../../../careers/careers.html" class="link link-theme link-arrow" style="
                display: inline-block;
                position: relative;
                border: none;
                padding-bottom: 4px;
                text-transform: uppercase;
                font-family: Montserrat, helvetica, arial, sans-serif;
                font-weight: 700
              ">CAREER PATHS</a></li>
              <li><a href="../../../competitives/competitive.html" class="link link-theme link-arrow" style="
                display: inline-block;
                position: relative;
                border: none;
                padding-bottom: 4px;
                text-transform: uppercase;
                font-family: Montserrat, helvetica, arial, sans-serif;
                font-weight: 700
              ">Competitive EXAMS</a></li></ul>
      </nav>
    <!-- ***********END OF NAVBAR *************-->
    <!-- UNITS -->
    <button class="collapsible" id="one">UNIT 1 - Introduction, Regular Expressions, Text Normalization and Edit
        Distance :</button>
    <div class="content">
        <p><a class="link" href="https://www.analyticsvidhya.com/blog/2021/06/part-13-step-by-step-guide-to-master-nlp-regular-expressions/" target="_blank">Regular
                Expressions</a>, <a class="link"
                href="https://www.scaler.com/topics/nlp/what-is-text-normalization-in-nlp/"
                target="_blank">Corpora Text Normalization</a>, <a class="link"
                href="https://www.ideserve.co.in/learn/edit-distance-dynamic-programming#:~:text=Minimum%20Edit%20distance%20between%20two,str1%20transforms%20str1%20into%20str2." target="_blank">Minimum Edit
                Distance</a>.<br><b>N-gram Language Models :</b> <a class="link"
                href="https://www.geeksforgeeks.org/n-gram-language-modelling-with-nltk/" target="_blank">N-Grams</a>, <a
                class="link" href="https://www.scaler.com/topics/nlp/language-models-in-nlp/" target="_blank">Evaluating Language
                Models</a>,
            <a class="link"
                href="https://thegradient.pub/frontiers-of-generalization-in-natural-language-processing/"
                target="_blank">Generalization and Zeros</a>, <a class="link"
                href="https://www.codingninjas.com/codestudio/library/smoothing-in-nlp"
                target="_blank">Smoothing</a>, <a class="link"
                href="https://smithamilli.com/blog/kneser-ney/"
                target="_blank">Kneser-Ney Smoothing</a>, <a class="link"
                href="https://rstudio-pubs-static.s3.amazonaws.com/253306_9828e2b22d314620b9d9f17fa6d8723e.html#/3"
                target="_blank">The Web and Stupid Backoff</a>, <a class="link"
                href="https://leimao.github.io/blog/Entropy-Perplexity/" target="_blank">Advanced: Perplexit's
                Relation to Entropy</a>.
        </p>
    </div>
    <button class="collapsible">UNIT 2 - Logistic Regression :</button>
    <div class="content">
        <p> <a class="link" href="https://towardsdatascience.com/sigmoid-and-softmax-functions-in-5-minutes-f516c80ea1f9#:~:text=Sigmoid%20is%20used%20for%20binary,extension%20of%20the%20Sigmoid%20function."
                target="_blank">
                Classification: the sigmoid</a>, <a class="link"
                href="https://www.capitalone.com/tech/machine-learning/what-is-logistic-regression/" target="_blank">Learning
                in LR</a>, <a class="link" href="https://neptune.ai/blog/cross-entropy-loss-and-its-applications-in-deep-learning"
                target="_blank">the cross-entropy loss function</a>,
            <a class="link"
                href="https://www.analyticsvidhya.com/blog/2021/03/understanding-gradient-descent-algorithm/"
                target="_blank">Gradient Descent</a>,
            <a class="link"
                href="https://www.simplilearn.com/tutorials/machine-learning-tutorial/regularization-in-machine-learning#:~:text=Regularization%20refers%20to%20techniques%20that,and%20prevent%20overfitting%20or%20underfitting."
                target="_blank">Regularization</a>,
            <a class="link"
                href="https://machinelearningmastery.com/multinomial-logistic-regression-with-python/"
                target="_blank">Multinomial logistic regression</a>,
            <a class="link"
                href="https://towardsdatascience.com/explainable-artificial-intelligence-part-2-model-interpretation-strategies-75d4afa6b739"
                target="_blank">interpreting models</a>,
            <a class="link"
                href="https://mccormickml.com/2014/03/04/gradient-descent-derivation/"
                target="_blank">Deriving the Gradient Equation</a>.<b>Vector Semantics :</b>
            <a class="link" href="https://www.tutorialspoint.com/natural_language_processing/natural_language_processing_semantic_analysis.htm#:~:text=Lexical%20Semantics,-The%20first%20part&text=It%20includes%20words%2C%20sub%2Dwords,sentences%20and%20syntax%20of%20sentence."
                target="_blank">Lexical Semantics</a>,
            <a class="link"
                href="https://medium.com/@ram.analytics1/an-introductory-notes-on-vector-semantics-tf-idf-model-and-a-toy-implementation-9046198bf7d#:~:text=Vector%20Semantics%20defines%20semantics%20%26%20interprets,and%20philosophical%20work%20of%201950s."
                target="_blank">Vector Semantics</a>,
            <a class="link"
                href="https://towardsdatascience.com/word-vectors-and-word-meaning-90493d13af76#:~:text=WHAT%20IS%20A%20WORD%20VECTOR,frequencies%20are%20represented%20with%20numbers."
                target="_blank">Words,Vectors</a>,
            <a class="link" href="https://www.geeksforgeeks.org/cosine-similarity/"
                target="_blank">Cosine for measuring similarity</a>,
            <a class="link"
                href="https://www.capitalone.com/tech/machine-learning/understanding-tf-idf/"
                target="_blank">TF-IDF</a>,
            <a class="link" href="https://nlp.stanford.edu/IR-book/html/htmledition/tf-idf-weighting-1.html" target="_blank">Weighing terms in the vector</a>,
            <a class="link"
                href="https://www.capitalone.com/tech/machine-learning/understanding-tf-idf/"
                target="_blank">Applications of the tf-idf vector model</a>,
            <a class="link" href="https://www.listendata.com/2022/06/pointwise-mutual-information-pmi.html?m=1" target="_blank">PMI</a>,
            <a class="link" href="https://www.analyticsvidhya.com/blog/2021/07/word2vec-for-word-embeddings-a-beginners-guide/" target="_blank">Word2vec</a>,
            <a class="link" href="https://www.kaggle.com/code/colinmorris/visualizing-embeddings-with-t-sne" target="_blank">Visualizing Embeddings</a>,
            <a class="link" href="http://www.offconvex.org/2015/12/12/word-embeddings-1/" target="_blank">Semantic properties</a>,
            <a class="link" href="https://blogs.ischool.berkeley.edu/w231/2021/05/31/machine-learning-bias-in-word-embedding-algorithms/" target="_blank">Bias,Embeddings</a>,
            <a class="link" href="https://www.r-bloggers.com/2020/07/evaluating-vector-space-models-with-word-analogies/" target="_blank">Evaluating Vector Models</a>.
        </p>
    </div>
    <button class="collapsible">UNIT 3 - Part-of-Speech Tagging :</button>
    <div class="content">
        <p> <a class="link" href="https://www3.diism.unisi.it/~maggini/Teaching/TEL/slides%20EN/06%20-%20NLP%20-%20PoS%20Tagging.pdf" target="_blank">English Word Classes</a>,<a class="link" href="https://www.sketchengine.eu/penn-treebank-tagset/#:~:text=English%20Penn%20Treebank%20part%2Dof%2Dspeech%20Tagset&text=Atagset%20is%20a%20list%20of,token%20in%20a%20text%20corpus." target="_blank">The Penn Treebank Part-of-Speech Tagset</a>, <a class="link" href="https://www.tutorialspoint.com/natural_language_processing/natural_language_processing_part_of_speech_tagging.htm"
                target="_blank">Part-of-Speech Tagging</a>, <a class="link" href="https://www.mygreatlearning.com/blog/pos-tagging/#:~:text=HMM%20(Hidden%20Markov%20Model)%20is,%2C%20partial%20discharges%2C%20and%20bioinformatics."
                target="_blank">HMM PoS Tagging</a>, <a class="link"
                href="https://devopedia.org/maximum-entropy-markov-model"
                target="_blank">Maximum Entropy Markov Models</a>, <a class="link"
                href="https://medium.com/@plusepsilon/the-bidirectional-language-model-1f3961d1fb27"
                target="_blank">Bidirectionality</a>, <a class="link"
                href="https://www.sketchengine.eu/blog/pos-tags/#:~:text=A%20POS%20tag%20(or%20part,text%20analysis%20tools%20and%20algorithms." target="_blank">Part-of-Speech Tagging for Other Languages</a>.<br><b>Sequence Processing with Recurrent Networks :</b> <a class="link"
                href="https://www.geeksforgeeks.org/introduction-to-recurrent-neural-network/"
                target="_blank"> Simple Recurrent Networks</a>, <a class="link"
                href="https://www.mygreatlearning.com/blog/recurrent-neural-network/" target="_blank">Applications of RNNs</a>, <a class="link"
                href="https://www.researchgate.net/figure/Illustrations-of-normal-RNN-stacked-RNN-and-bidirectional-RNN_fig7_311839720" target="_blank"> Deep Networks: Stacked and Bidirectional RNNs</a>, <a class="link"
                href="https://neptune.ai/blog/recurrent-neural-network-guide" target="_blank"> Managing Context in RNNs</a>, <a class="link"
                href="https://www.analyticsvidhya.com/blog/2022/01/tutorial-on-rnn-lstm-gru-with-implementation/" target="_blank"> LSTMs and GRUs</a>, <a class="link"
                href="https://www.freecodecamp.org/news/evolution-of-tokenization/" target="_blank">Words, Characters and Byte-Pairs</a>.
        </p>
    </div>
    <button class="collapsible">UNIT 4 - Statistical Parsing :</button>
    <div class="content">
        <p> <a class="link" href="https://www.exploredatabase.com/2020/05/formal-definition-of-probabilistic-context-free-grammar-pcfg-with-example.html"
                target="_blank">Probabilistic Context-Free Grammars</a>, <a class="link"
                href="https://www.datasciencecentral.com/some-nlp-probabilistic-context-free-grammar-pcfg-and-cky-parsing/"
                target="_blank">Probabilistic CKY Parsing of PCFGs</a>, <a class="link"
                href="https://www.exploredatabase.com/2020/04/how-to-calculated-probabilities-for-PCFG-using-treebanks.html"
                target="_blank">
                Ways to Learn PCFG Rule Probabilities</a>,
            <a class="link"
                href="https://cs.pomona.edu/~kim/CSC181S08/lectures/Lec12/Lec12.pdf"
                target="_blank"> Problems with PCFGs</a>, <a class="link"
                href="https://youtu.be/ZzXzYvWkbn8"
                target="_blank">Improving PCFGs by Splitting Non-Terminals</a>, <a class="link"
                href="https://youtu.be/ubcsi4djGig"
                target="_blank">Probabilistic Lexicalized CFGs</a>, <a class="link"
                href="https://youtu.be/iCy9nGTYNdo"
                target="_blank">Probabilistic CCG Parsing</a>, <a class="link"
                href="https://wiki.eecs.yorku.ca/course_archive/2014-15/W/6339/_media/10e-eval-2x3.pdf" target="_blank">Evaluating Parsers</a>, <a class="link"
                href="https://www.catalyzex.com/s/Human%20Parsing" target="_blank">Human Parsing</a>.<br><b>Dependency Parsing : </b> <a class="link"
                href="https://www.analyticsvidhya.com/blog/2021/12/dependency-parsing-in-natural-language-processing-with-examples/" target="_blank">Dependency Relations</a>, <a class="link"
                href="http://www.cs.cmu.edu/~sleator/paper/node19.html" target="_blank">Dependency Formalisms</a>, <a class="link"
                href="https://aclanthology.org/W05-1714.pdf" target="_blank">Dependency Treebanks</a>, <a class="link"
                href="https://youtu.be/oLHnqGmQtI4" target="_blank">Transition-Based Dependency Parsing</a>, <a class="link"
                href="https://youtu.be/dOCRzahEL84" target="_blank">Graph-Based Dependency Parsing</a>, <a class="link"
                href="https://youtu.be/hgaeB2JloJY" target="_blank">Evaluation</a>.
        </p>
    </div>
    <button class="collapsible">UNIT 5 - Computational Semantics, Semantic Parsing, Information Extraction :</button>
    <div class="content">
        <p> <a class="link" href="https://towardsdatascience.com/named-entity-recognition-with-nltk-and-spacy-8c4a7d88e7da" target="_blank">
            Named Entity Recognition</a>, <a class="link"
                href="http://nlpprogress.com/english/relationship_extraction.html"
                target="_blank">
                Relation Extraction</a>, <a class="link"
                href="https://www.qualicen.de/natural-language-processing-timeline-extraction-with-regexes-and-spacy/#"
                target="_blank">Extracting Times</a>,
            <a class="link"
                href="https://towardsdatascience.com/natural-language-processing-event-extraction-f20d634661d3#:~:text=Extracting%20events%20from%20news%20articles&text=One%20of%20its%20common%20applications,happened%20and%20when%20it%20happened."
                target="_blank">Extracting Events and their Times</a>,
            <a class="link" href="https://aclanthology.org/2021.naacl-main.70.pdf"
                target="_blank">Template Filling</a>.
        </p>
    </div>
    <button class="collapsible" id="pp"><a href="../sem7/qb.html" target="_blank">PREVIOUS PAPERS : </a></button>
    <div class="content">
        <p></p>
    </div>

    <!-- FOOTER SECTION -->
    <footer class="footer">
        <div class="container footer_container">
            <div class="footer_1">
                <a href="../../../index.html" class="footer-logo">
                    <h4>TRAJECTORY</h4>
                </a>
                <p>
                    Chart your path to Success !                </p>
            </div>
            <div class="footer_2">
                <h4>Permalinks</h4>
                <ul class="permalinks">
                    <li><a href="../../../index.html">Home</a></li>
                    <li><a href="../../academics.html">Academics</a></li>
                    <li><a href="../../../careers/careers.html">Career Paths</a></li>
                    <li><a href="../../../competitives/competitive.html">Competitive Exams</a></li>
                </ul>
            </div>
            <div class="footer_3">
                <h4>Contact Us</h4>
                <div>
                    <p>
                        <i> <a href="https://www.instagram.com/thetrajectoryyy/" target="_blank"><img
                                    style="width: 60px; display: inline;"
                                    src="../../../Instagram-Logo.wine.svg"></a></i>/ @thetrajectoryyy
                    </p>
                    <p>
                        <i><a href="https://twitter.com/thetrajectoryyy" target="_blank"><img
                                    style="width: 60px;display: inline;" src="../../../Twitter-Logo.wine.svg"></a></i>/
                        @thetrajectoryyy
                    </p>

                    <p>

                        <i><a href="https://t.me/+Ne8jNS3_f7hhNjQ1" target="_blank"><img
                                    style="width: 60px;display: inline;"
                                    src="../../../Telegram_(software)-Classic-Logo.wine.svg"></a></i>/ The Trajectory
                    </p>
                    <br>
                    <p>
                        <i><img style="width: 30px;display: inline;margin-right: 10px;"
                                src="../../../Gmail_Logo.svg"></a></i><a
                            href="mailto:trajectory.thepath@gmail.com">trajectory.thepath@gmail.com</a>
                    </p>



                </div>
            </div>
        </div>
    </footer>
    <script src="../../../home.js"></script>
    <script src="../semstyle.js"></script>
</body>

</html>